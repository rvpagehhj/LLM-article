# LLM-article

### :star2: Recommendations :star2:
- **Transformer:** Attention Is All You Need. [[paper](https://arxiv.org/abs/1706.03762)]
- **Bert:** BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. [[paper](https://arxiv.org/abs/1810.04805)]
- **GPT3:** Language Models are Few-Shot Learners. [[paper](https://arxiv.org/abs/2005.14165)]
- **MoE:** GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding. [[paper](https://arxiv.org/abs/2006.16668)]
- **LoRA:** LoRA: Low-Rank Adaptation of Large Language Models. [[paper](https://arxiv.org/abs/2106.09685)]
- **CLIP:** Learning Transferable Visual Models From Natural Language Supervision. [[paper](https://arxiv.org/abs/2103.00020)]
***
- **Embodied AI:** PaLM-E: An Embodied Multimodal Language Model. [[paper](https://arxiv.org/abs/2303.03378)]
- **CoT:** Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. [[paper](https://arxiv.org/abs/2201.11903)]
- **RAG:** Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. [[paper](https://arxiv.org/abs/2005.11401)]
- **MCP:** Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions. [[paper](https://arxiv.org/abs/2503.23278)]
- **RLHF:** Training language models to follow instructions with human feedback. [[paper](https://arxiv.org/abs/2203.02155)]
- **ReAct:** ReAct: Synergizing Reasoning and Acting in Language Models. [[paper](https://arxiv.org/abs/2210.03629)]
- **Voyager:** Voyager: An Open-Ended Embodied Agent with Large Language Models. [[paper](https://arxiv.org/abs/2305.16291)]
***
- **PPO:** Proximal Policy Optimization Algorithms. [[paper](https://arxiv.org/abs/1707.06347)]
- **GRPO:** Group-in-Group Policy Optimization for LLM Agent Training. [[paper](https://arxiv.org/abs/2505.10978)]
***
- **DeepSeek V3:** DeepSeek-V3 Technical Report. [[paper](https://arxiv.org/abs/2412.19437)]
- **Qwen:** Qwen Technical Report. [[paper](https://arxiv.org/abs/2309.16609)]
